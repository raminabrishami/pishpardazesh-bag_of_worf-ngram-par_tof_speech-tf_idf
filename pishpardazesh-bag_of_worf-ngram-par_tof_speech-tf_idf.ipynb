{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc69066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mahnaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mahnaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mahnaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mahnaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mahnaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk import pos_tag\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from nltk import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.collocations import *\n",
    "from nltk.collocations import BigramCollocationFinder,TrigramCollocationFinder,QuadgramCollocationFinder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe93748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(matn_vorodi):\n",
    "    \n",
    "    global stemmer_words\n",
    "    global filtered_list\n",
    "    global fixd_stemmer_words\n",
    "    global text\n",
    "    global token\n",
    "    \n",
    "    text = open(matn_vorodi, \"r\")\n",
    "    \n",
    "    text=text.read()\n",
    "    token=word_tokenize(text)\n",
    "    \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    filtered_list = []\n",
    "    for word in token:\n",
    "        if word.casefold() not in stop_words:\n",
    "             filtered_list.append(word)\n",
    "                \n",
    "    stemmer = PorterStemmer()\n",
    "    stemmer_words = [stemmer.stem(word) for word in filtered_list]\n",
    "    \n",
    "    cc=stemmer_words.count('.')\n",
    "    for i in range(cc):\n",
    "        stemmer_words.remove('.')\n",
    "        \n",
    "    cx=stemmer_words.count(',')\n",
    "    for i in range(cx):\n",
    "        stemmer_words.remove(',')\n",
    "    \n",
    "    fixd_stemmer_words=' '.join(stemmer_words)\n",
    "    \n",
    "    print(fixd_stemmer_words)\n",
    "    \n",
    "    \n",
    "def bag_of_words():\n",
    "    \n",
    "    global unic_text\n",
    "    global bag_of_text\n",
    "    \n",
    "    unic_text=[]\n",
    "    for i in stemmer_words:\n",
    "        if i not in unic_text:\n",
    "            unic_text.append(i)\n",
    "    print('unic_text : ', unic_text)\n",
    "    print(\"\\n\")\n",
    "    bag_of_text = {}\n",
    "    for i in stemmer_words:\n",
    "        word = i.lower()\n",
    "        if word in bag_of_text:\n",
    "            bag_of_text[word] += 1\n",
    "        else:\n",
    "            bag_of_text[word] = 1\n",
    "\n",
    "    print ('bag_of_text : ',bag_of_text)\n",
    "    \n",
    "    n_words_set=len(bag_of_text.keys())\n",
    "    b=list(bag_of_text.values())\n",
    "    df_tf=pd.DataFrame(np.zeros((1, n_words_set)),columns=bag_of_text.keys())\n",
    "    i=0\n",
    "    for w in bag_of_text.keys():\n",
    "        df_tf[w] = b[i]\n",
    "        i+=1\n",
    "    return df_tf\n",
    "    \n",
    "    \n",
    "def N_gram(n):\n",
    "    \n",
    "    \n",
    "    CountVec = CountVectorizer(ngram_range=(n,n))\n",
    "\n",
    "    Count_data = CountVec.fit_transform([fixd_stemmer_words])\n",
    "    \n",
    "    cv_dataframe=pd.DataFrame(Count_data.toarray(),columns=CountVec.get_feature_names())\n",
    "    print (cv_dataframe)\n",
    "    \n",
    "    print( )\n",
    "\n",
    "    print(\"tf_idf Without Smoothing:\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    tf_idf_vec = TfidfVectorizer(use_idf=True, \n",
    "                            smooth_idf=False,  \n",
    "                            ngram_range=(n,n),stop_words='english')\n",
    "\n",
    "    tf_idf_data = tf_idf_vec.fit_transform([fixd_stemmer_words])\n",
    "\n",
    "\n",
    "    tf_idf_dataframe=pd.DataFrame(tf_idf_data.toarray(),columns=tf_idf_vec.get_feature_names())\n",
    "    print(tf_idf_dataframe)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    tf_idf_vec_smooth = TfidfVectorizer(use_idf=True,  \n",
    "                            smooth_idf=True,  \n",
    "                            ngram_range=(n,n),stop_words='english')\n",
    "\n",
    "\n",
    "    tf_idf_data_smooth = tf_idf_vec_smooth.fit_transform([fixd_stemmer_words])\n",
    "\n",
    "    print(\"tf_idf With Smoothing:\")\n",
    "    print(\"\\n\")\n",
    "    tf_idf_dataframe_smooth=pd.DataFrame(tf_idf_data_smooth.toarray(),columns=tf_idf_vec_smooth.get_feature_names())\n",
    "    print (tf_idf_dataframe_smooth)\n",
    "    \n",
    "    \n",
    "def tf_idf():\n",
    "    \n",
    "    n_docs = 1    \n",
    "    n_words_set = len(unic_text)\n",
    "\n",
    "    df_tf = pd.DataFrame(np.zeros((n_docs, n_words_set)), columns=unic_text)\n",
    "\n",
    "    for w in stemmer_words:\n",
    "        df_tf[w] = df_tf[w] + (1 / len(token))\n",
    "        \n",
    "    dictt={}\n",
    "    column=df_tf.columns\n",
    "    for i in column:\n",
    "        dictt[i]=df_tf[i][0]\n",
    "\n",
    "    print(dictt)\n",
    "    \n",
    "    return df_tf\n",
    "    \n",
    "    \n",
    "def part_of_speech():\n",
    "    \n",
    "    text_tag=pos_tag(unic_text)\n",
    "    print(text_tag)\n",
    "\n",
    "    \n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    onehot = encoder.fit_transform(text_tag)\n",
    "    print('\\n')\n",
    "    print('onehot encoder: ')\n",
    "    print('\\n')\n",
    "    print(onehot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cc36bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muad'dib learn rapidli first train learn first lesson basic trust could learn 's shock find mani peopl believ learn mani believ learn difficult\n"
     ]
    }
   ],
   "source": [
    "preprocess('D://textt.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc09ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unic_text :  [\"muad'dib\", 'learn', 'rapidli', 'first', 'train', 'lesson', 'basic', 'trust', 'could', \"'s\", 'shock', 'find', 'mani', 'peopl', 'believ', 'difficult']\n",
      "\n",
      "\n",
      "bag_of_text :  {\"muad'dib\": 1, 'learn': 5, 'rapidli': 1, 'first': 2, 'train': 1, 'lesson': 1, 'basic': 1, 'trust': 1, 'could': 1, \"'s\": 1, 'shock': 1, 'find': 1, 'mani': 2, 'peopl': 1, 'believ': 2, 'difficult': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>muad'dib</th>\n",
       "      <th>learn</th>\n",
       "      <th>rapidli</th>\n",
       "      <th>first</th>\n",
       "      <th>train</th>\n",
       "      <th>lesson</th>\n",
       "      <th>basic</th>\n",
       "      <th>trust</th>\n",
       "      <th>could</th>\n",
       "      <th>'s</th>\n",
       "      <th>shock</th>\n",
       "      <th>find</th>\n",
       "      <th>mani</th>\n",
       "      <th>peopl</th>\n",
       "      <th>believ</th>\n",
       "      <th>difficult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   muad'dib  learn  rapidli  first  train  lesson  basic  trust  could  's  \\\n",
       "0         1      5        1      2      1       1      1      1      1   1   \n",
       "\n",
       "   shock  find  mani  peopl  believ  difficult  \n",
       "0      1     1     2      1       2          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e57555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   basic  believ  could  dib  difficult  find  first  learn  lesson  mani  \\\n",
      "0      1       2      1    1          1     1      2      5       1     2   \n",
      "\n",
      "   muad  peopl  rapidli  shock  train  trust  \n",
      "0     1      1        1      1      1      1  \n",
      "\n",
      "tf_idf Without Smoothing:\n",
      "\n",
      "\n",
      "      basic    believ       dib  difficult     learn    lesson      mani  \\\n",
      "0  0.152499  0.304997  0.152499   0.152499  0.762493  0.152499  0.304997   \n",
      "\n",
      "       muad     peopl   rapidli     shock     train     trust  \n",
      "0  0.152499  0.152499  0.152499  0.152499  0.152499  0.152499  \n",
      "\n",
      "\n",
      "tf_idf With Smoothing:\n",
      "\n",
      "\n",
      "      basic    believ       dib  difficult     learn    lesson      mani  \\\n",
      "0  0.152499  0.304997  0.152499   0.152499  0.762493  0.152499  0.304997   \n",
      "\n",
      "       muad     peopl   rapidli     shock     train     trust  \n",
      "0  0.152499  0.152499  0.152499  0.152499  0.152499  0.152499  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahnaz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\mahnaz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\mahnaz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "N_gram(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63b82379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"muad'dib\": 0.018867924528301886, 'learn': 0.09433962264150943, 'rapidli': 0.018867924528301886, 'first': 0.03773584905660377, 'train': 0.018867924528301886, 'lesson': 0.018867924528301886, 'basic': 0.018867924528301886, 'trust': 0.018867924528301886, 'could': 0.018867924528301886, \"'s\": 0.018867924528301886, 'shock': 0.018867924528301886, 'find': 0.018867924528301886, 'mani': 0.03773584905660377, 'peopl': 0.018867924528301886, 'believ': 0.03773584905660377, 'difficult': 0.018867924528301886}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>muad'dib</th>\n",
       "      <th>learn</th>\n",
       "      <th>rapidli</th>\n",
       "      <th>first</th>\n",
       "      <th>train</th>\n",
       "      <th>lesson</th>\n",
       "      <th>basic</th>\n",
       "      <th>trust</th>\n",
       "      <th>could</th>\n",
       "      <th>'s</th>\n",
       "      <th>shock</th>\n",
       "      <th>find</th>\n",
       "      <th>mani</th>\n",
       "      <th>peopl</th>\n",
       "      <th>believ</th>\n",
       "      <th>difficult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.018868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   muad'dib    learn   rapidli     first     train    lesson     basic  \\\n",
       "0  0.018868  0.09434  0.018868  0.037736  0.018868  0.018868  0.018868   \n",
       "\n",
       "      trust     could        's     shock      find      mani     peopl  \\\n",
       "0  0.018868  0.018868  0.018868  0.018868  0.018868  0.037736  0.018868   \n",
       "\n",
       "     believ  difficult  \n",
       "0  0.037736   0.018868  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "282cf009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"muad'dib\", 'NN'), ('learn', 'NN'), ('rapidli', 'NN'), ('first', 'RB'), ('train', 'VB'), ('lesson', 'NN'), ('basic', 'JJ'), ('trust', 'NN'), ('could', 'MD'), (\"'s\", 'POS'), ('shock', 'NN'), ('find', 'VBP'), ('mani', 'JJ'), ('peopl', 'NN'), ('believ', 'NN'), ('difficult', 'JJ')]\n",
      "\n",
      "\n",
      "onehot encoder: \n",
      "\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "part_of_speech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73abc49d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
